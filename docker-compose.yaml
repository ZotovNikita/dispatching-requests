services:
  ollama:
    volumes:
      - ${LOCAL_OLLAMA_MODELS}:/opt/.ollama
    container_name: ollama
    pull_policy: always
    tty: true
    restart: always
    image: ollama/ollama:latest
    ports:
      - ${OLLAMA_PORT}:11434
    environment:
      - OLLAMA_HOST=0.0.0.0:11434
      - OLLAMA_MODELS=/opt/.ollama
      - OLLAMA_ORIGINS=*
    networks:
      - sila-net
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  backend:
    build:
      context: .
      dockerfile: ./Dockerfile
    container_name: backend
    restart: always
    ports:
      - ${BACKEND_PORT}:${BACKEND_PORT}
    environment:
      - APP__TITLE=${BACKEND_TITLE}
      - APP__HOST=${BACKEND_HOST}
      - APP__PORT=${BACKEND_PORT}
    env_file:
      - .env
    depends_on:
      - ollama
    networks:
      - sila-net

  streamlit:
    build:
      context: .
      dockerfile: ./Dockerfile.streamlit
    container_name: streamlit
    restart: always
    ports:
      - ${FRONTEND_PORT}:8501
    env_file:
      - .env
    depends_on:
      - backend
    networks:
      - sila-net

networks:
  sila-net:
    driver: bridge
